"""Program to generate new split of a given dataset.

This file contains functions required to generate new splits of a given dataset.
Additionally, the new split generated will have the same distribution (intents)
as that of the original dataset. The split is generated by randomly selecting
a fraction of the given dataset for each intent separately.

  Typical usage example:

  python splitter.py --output_dir='./split_data_30/snips' --train_data_path='./data/snips/train' --test_data_path='./data/snips/test' --valid_data_path='./data/snips/valid'
"""

import os
import argparse
import logging
import sys
import numpy as np
import math 
from collections import defaultdict


def compute_distribution(path):
  '''
  This function computes the distribution of a given split of the dataset.
  '''
  count = defaultdict(int)
  total_count = 0.0
  with open(path, 'r') as fd:
    for line in fd:
      label = line.rstrip('\r\n')
      count[label] += 1
      total_count += 1
    
  print("The distribution is as follows:")
  for label in count.keys():
    print("{} : {:.4f}%".format(label, (count[label]/total_count)*100))


def group_intents(input_file, intent_file, slot_file):
  '''
  This function groups the dataset based on the intents and returns it.
  '''
  intent_groups = defaultdict(list)
    
  with open(input_file, 'r') as input_fd, \
       open(intent_file, 'r') as intent_fd, \
       open(slot_file, 'r') as slot_fd:
    
      for ip, intent, slot in zip(input_fd, intent_fd, slot_fd):
        ip, intent, slot = ip.rstrip('\r\n'), intent.rstrip('\r\n'), slot.rstrip('\r\n') 
        intent_groups[intent].append((ip, slot))

  return intent_groups


def generate_split(intent_groups, split_val):
  '''
  This function creates the new split.
  '''

  split_dataset = defaultdict(list)
  for intent, val in intent_groups.items():
    cur_size = len(val)
    new_size = math.ceil(cur_size*split_val)
    
    idx_list = np.arange(cur_size)
    np.random.shuffle(idx_list)
    
    split_idx_list = idx_list[:new_size]
    split_dataset[intent] = [val[idx] for idx in split_idx_list]
    
  return split_dataset


def save_dataset(dataset, output_dir):
  '''
  This function saves the split dataset to the disk.
  '''

  input_file = os.path.join(output_dir, "seq.in")
  intent_file = os.path.join(output_dir, "label")
  slot_file = os.path.join(output_dir, "seq.out")
    
  with open(input_file, 'w+') as input_fd, \
       open(intent_file, 'w+') as intent_fd, \
       open(slot_file, 'w+') as slot_fd:
  
    for intent, val in dataset.items():
      for (ip, slot) in val:
        input_fd.write(ip + '\n')
        intent_fd.write(intent + '\n')        
        slot_fd.write(slot + '\n')        


def split(input_file, intent_file, slot_file, output_dir, split_val=0.3):
  '''
  This function creates a new split of the dataset while having the same distribution (intent)
  as the original dataset.
  '''

  intent_groups = group_intents(input_file, intent_file, slot_file)
  split_dataset = generate_split(intent_groups, split_val)
  save_dataset(split_dataset, output_dir)


def main():
  parser = argparse.ArgumentParser(allow_abbrev=False)
  parser.add_argument("--split_val", type=float, default=0.3, help="The fraction of the original dataset to be used to create the new dataset ")
  parser.add_argument("--train_data_path", type=str, default='./data/atis/train', help="Path to training data files.")
  parser.add_argument("--test_data_path", type=str, default='./data/atis/test', help="Path to testing data files.")
  parser.add_argument("--valid_data_path", type=str, default='./data/atis/valid', help="Path to validation data files.")
  parser.add_argument("--input_file", type=str, default='seq.in', help="Input file name.")
  parser.add_argument("--slot_file", type=str, default='seq.out', help="Slot file name.")
  parser.add_argument("--intent_file", type=str, default='label', help="Intent file name.")

  parser.add_argument("--output_dir", type=str, default=None, help="Path to save the new dataset.")

  arg = parser.parse_args()

  if arg.output_dir == None:
    print('Output directory cannot be empty')
    exit(1)

  #Split train, test and valid dataset
  out_train_dir, out_valid_dir, out_test_dir = \
    os.path.join(arg.output_dir, "train"), os.path.join(arg.output_dir, "valid"), os.path.join(arg.output_dir, "test")

  train_input_path = os.path.join(arg.train_data_path, arg.input_file)
  train_intent_path = os.path.join(arg.train_data_path, arg.intent_file)
  train_slot_path = os.path.join(arg.train_data_path, arg.slot_file)

  valid_input_path = os.path.join(arg.valid_data_path, arg.input_file)
  valid_intent_path = os.path.join(arg.valid_data_path, arg.intent_file)
  valid_slot_path = os.path.join(arg.valid_data_path, arg.slot_file)

  test_input_path = os.path.join(arg.test_data_path, arg.input_file)
  test_intent_path = os.path.join(arg.test_data_path, arg.intent_file)
  test_slot_path = os.path.join(arg.test_data_path, arg.slot_file)
  
  split(train_input_path, train_intent_path, train_slot_path, out_train_dir, arg.split_val)
  split(valid_input_path, valid_intent_path, valid_slot_path, out_valid_dir, arg.split_val)
  split(test_input_path, test_intent_path, test_slot_path, out_test_dir, arg.split_val)


if __name__ == '__main__':
  main()

